{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Risk Models Using Tree-based Models.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dOvOYD2dlHID"
      },
      "outputs": [],
      "source": [
        "import shap\n",
        "import sklearn\n",
        "import itertools\n",
        "import pydotplus\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from IPython.display import Image \n",
        "\n",
        "from sklearn.tree import export_graphviz\n",
        "from sklearn.externals.six import StringIO\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer, SimpleImputer\n",
        "\n",
        "# We'll also import some helper functions that will be useful later on.\n",
        "from util import load_data, cindex"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "aT_8G6_FlJPT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_dev, X_test, y_dev, y_test = load_data(10)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_dev, y_dev, test_size=0.25, random_state=10)"
      ],
      "metadata": {
        "id": "2pdp9_w5lIlN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"X_train shape: {}\".format(X_train.shape))\n",
        "X_train.head()"
      ],
      "metadata": {
        "id": "uvwJt5RnlIoD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.head(20)"
      ],
      "metadata": {
        "id": "5bcPlSZ_lIrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = 10\n",
        "print(X_train.iloc[i,:])\n",
        "print(\"\\nDied within 10 years? {}\".format(y_train.loc[y_train.index[i]]))"
      ],
      "metadata": {
        "id": "kmf7NBvflIuU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dealing with missing data"
      ],
      "metadata": {
        "id": "nbH2EA6dlZD0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(X_train.isnull(), cbar=False)\n",
        "plt.title(\"Training\")\n",
        "plt.show()\n",
        "\n",
        "sns.heatmap(X_val.isnull(), cbar=False)\n",
        "plt.title(\"Validation\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5g4jVvoslWgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fraction_rows_missing(df):\n",
        "    '''\n",
        "    Return percent of rows with any missing\n",
        "    data in the dataframe. \n",
        "    \n",
        "    Input:\n",
        "        df (dataframe): a pandas dataframe with potentially missing data\n",
        "    Output:\n",
        "        frac_missing (float): fraction of rows with missing data\n",
        "    '''\n",
        "    # a=len(df)\n",
        "    # df_dp=df.dropna()\n",
        "    # b=len(df_dp)\n",
        "    # return (a-b)/a\n",
        "    return np.sum(pd.DataFrame.any(df.isnull(),axis = 1)) / df.shape[0] "
      ],
      "metadata": {
        "id": "LZCPxUUxlWjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pd.DataFrame({'a':[None, 1, 1, None], 'b':[1, None, 0, 1]})\n",
        "print(\"Example dataframe:\\n\")\n",
        "print(df_test)\n",
        "\n",
        "print(\"\\nComputed fraction missing: {}, expected: {}\".format(fraction_rows_missing(df_test), 0.75))\n",
        "print(f\"Fraction of rows missing from X_train: {fraction_rows_missing(X_train):.3f}\")\n",
        "print(f\"Fraction of rows missing from X_val: {fraction_rows_missing(X_val):.3f}\")\n",
        "print(f\"Fraction of rows missing from X_test: {fraction_rows_missing(X_test):.3f}\")"
      ],
      "metadata": {
        "id": "f1VkI1OSlWlp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_dropped = X_train.dropna(axis='rows')\n",
        "y_train_dropped = y_train.loc[X_train_dropped.index]\n",
        "X_val_dropped = X_val.dropna(axis='rows')\n",
        "y_val_dropped = y_val.loc[X_val_dropped.index]"
      ],
      "metadata": {
        "id": "bns4MWx_lWoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decision Trees"
      ],
      "metadata": {
        "id": "mCfbSL4WloZ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dt = DecisionTreeClassifier(max_depth=None, random_state=10)\n",
        "dt.fit(X_train_dropped, y_train_dropped)"
      ],
      "metadata": {
        "id": "fM7uo002lpkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_preds = dt.predict_proba(X_train_dropped)[:, 1]\n",
        "print(f\"Train C-Index: {cindex(y_train_dropped.values, y_train_preds)}\")\n",
        "\n",
        "\n",
        "y_val_preds = dt.predict_proba(X_val_dropped)[:, 1]\n",
        "print(f\"Val C-Index: {cindex(y_val_dropped.values, y_val_preds)}\")"
      ],
      "metadata": {
        "id": "jhbkvU4OlpnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt_hyperparams = {'max_depth':20,'criterion':'gini','min_samples_split':0.5}"
      ],
      "metadata": {
        "id": "N7JJxxZklpp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt_reg = DecisionTreeClassifier(**dt_hyperparams, random_state=10)\n",
        "dt_reg.fit(X_train_dropped, y_train_dropped)\n",
        "\n",
        "y_train_preds = dt_reg.predict_proba(X_train_dropped)[:, 1]\n",
        "y_val_preds = dt_reg.predict_proba(X_val_dropped)[:, 1]\n",
        "print(f\"Train C-Index: {cindex(y_train_dropped.values, y_train_preds)}\")\n",
        "print(f\"Val C-Index (expected > 0.6): {cindex(y_val_dropped.values, y_val_preds)}\")"
      ],
      "metadata": {
        "id": "-CqOAm8OlIxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dot_data = StringIO()\n",
        "export_graphviz(dt_reg, feature_names=X_train_dropped.columns, out_file=dot_data,  \n",
        "                filled=True, rounded=True, proportion=True, special_characters=True,\n",
        "                impurity=False, class_names=['neg', 'pos'], precision=2)\n",
        "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
        "Image(graph.create_png())"
      ],
      "metadata": {
        "id": "A5BmFW9Hl8t_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest"
      ],
      "metadata": {
        "id": "jOQ9wMHAl_7h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(n_estimators=100, random_state=10)\n",
        "rf.fit(X_train_dropped, y_train_dropped)"
      ],
      "metadata": {
        "id": "F7q1qgWrmCdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_rf_preds = rf.predict_proba(X_train_dropped)[:, 1]\n",
        "print(f\"Train C-Index: {cindex(y_train_dropped.values, y_train_rf_preds)}\")\n",
        "\n",
        "y_val_rf_preds = rf.predict_proba(X_val_dropped)[:, 1]\n",
        "print(f\"Val C-Index: {cindex(y_val_dropped.values, y_val_rf_preds)}\")"
      ],
      "metadata": {
        "id": "XQppJ8yEl8w8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def holdout_grid_search(clf, X_train_hp, y_train_hp, X_val_hp, y_val_hp, hyperparams, fixed_hyperparams={}):\n",
        "    '''\n",
        "    Conduct hyperparameter grid search on hold out validation set. Use holdout validation.\n",
        "    Hyperparameters are input as a dictionary mapping each hyperparameter name to the\n",
        "    range of values they should iterate over. Use the cindex function as your evaluation\n",
        "    function.\n",
        "\n",
        "    Input:\n",
        "        clf: sklearn classifier\n",
        "        X_train_hp (dataframe): dataframe for training set input variables\n",
        "        y_train_hp (dataframe): dataframe for training set targets\n",
        "        X_val_hp (dataframe): dataframe for validation set input variables\n",
        "        y_val_hp (dataframe): dataframe for validation set targets\n",
        "        hyperparams (dict): hyperparameter dictionary mapping hyperparameter\n",
        "                            names to range of values for grid search\n",
        "        fixed_hyperparams (dict): dictionary of fixed hyperparameters that\n",
        "                                  are not included in the grid search\n",
        "\n",
        "    Output:\n",
        "        best_estimator (sklearn classifier): fitted sklearn classifier with best performance on\n",
        "                                             validation set\n",
        "        best_hyperparams (dict): hyperparameter dictionary mapping hyperparameter\n",
        "                                 names to values in best_estimator\n",
        "    '''\n",
        "    best_estimator = None\n",
        "    best_hyperparams = {}\n",
        "    \n",
        "    # hold best running score\n",
        "    best_score = 0.0\n",
        "\n",
        "    # get list of param values\n",
        "    lists = hyperparams.values()\n",
        "    \n",
        "    # get all param combinations\n",
        "    param_combinations = list(itertools.product(*lists))\n",
        "    total_param_combinations = len(param_combinations)\n",
        "\n",
        "    # iterate through param combinations\n",
        "    for i, params in enumerate(param_combinations, 1):\n",
        "        # fill param dict with params\n",
        "        param_dict = {}\n",
        "        for param_index, param_name in enumerate(hyperparams):\n",
        "            param_dict[param_name] = params[param_index]\n",
        "            \n",
        "        # create estimator with specified params\n",
        "        estimator = clf(**param_dict, **fixed_hyperparams)\n",
        "\n",
        "        # fit estimator\n",
        "        estimator.fit(X_train_hp, y_train_hp)\n",
        "        \n",
        "        # get predictions on validation set\n",
        "        preds = estimator.predict_proba(X_val_hp)\n",
        "        \n",
        "        # compute cindex for predictions\n",
        "        estimator_score = cindex(y_val_hp, preds[:,1])\n",
        "\n",
        "        print(f'[{i}/{total_param_combinations}] {param_dict}')\n",
        "        print(f'Val C-Index: {estimator_score}\\n')\n",
        "\n",
        "        # if new high score, update high score, best estimator\n",
        "        # and best params \n",
        "        if estimator_score >= best_score:\n",
        "                best_score = estimator_score\n",
        "                best_estimator = estimator\n",
        "                best_hyperparams = param_dict\n",
        "\n",
        "    # add fixed hyperparamters to best combination of variable hyperparameters\n",
        "    best_hyperparams.update(fixed_hyperparams)\n",
        "    \n",
        "    return best_estimator, best_hyperparams"
      ],
      "metadata": {
        "id": "YFJLmZm5l8z7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_forest_grid_search(X_train_dropped, y_train_dropped, X_val_dropped, y_val_dropped):\n",
        "\n",
        "    # Define ranges for the chosen random forest hyperparameters \n",
        "    hyperparams = {\n",
        "        # how many trees should be in the forest (int)\n",
        "        # 'n_estimators': [20,50,100],\n",
        "        'n_estimators': [10],\n",
        "        # the maximum depth of trees in the forest (int)\n",
        "        \n",
        "        'max_depth': [5],\n",
        "        \n",
        "        # the minimum number of samples in a leaf as a fraction\n",
        "        # of the total number of samples in the training set\n",
        "        # Can be int (in which case that is the minimum number)\n",
        "        # or float (in which case the minimum is that fraction of the\n",
        "        # number of training set samples)\n",
        "        'min_samples_leaf': [1],\n",
        "\n",
        "    }\n",
        "\n",
        "    \n",
        "    fixed_hyperparams = {\n",
        "        'random_state': 10,\n",
        "    }\n",
        "    \n",
        "    rf = RandomForestClassifier\n",
        "\n",
        "    best_rf, best_hyperparams = holdout_grid_search(rf, X_train_dropped, y_train_dropped,\n",
        "                                                    X_val_dropped, y_val_dropped, hyperparams,\n",
        "                                                    fixed_hyperparams)\n",
        "\n",
        "    print(f\"Best hyperparameters:\\n{best_hyperparams}\")\n",
        "\n",
        "    \n",
        "    y_train_best = best_rf.predict_proba(X_train_dropped)[:, 1]\n",
        "    print(f\"Train C-Index: {cindex(y_train_dropped, y_train_best)}\")\n",
        "\n",
        "    y_val_best = best_rf.predict_proba(X_val_dropped)[:, 1]\n",
        "    print(f\"Val C-Index: {cindex(y_val_dropped, y_val_best)}\")\n",
        "    \n",
        "    # add fixed hyperparamters to best combination of variable hyperparameters\n",
        "    best_hyperparams.update(fixed_hyperparams)\n",
        "    \n",
        "    return best_rf, best_hyperparams"
      ],
      "metadata": {
        "id": "oh5DKJ5AmLRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_rf, best_hyperparams = random_forest_grid_search(X_train_dropped, y_train_dropped, X_val_dropped, y_val_dropped)"
      ],
      "metadata": {
        "id": "digCptRzmLUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_best = best_rf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(f\"Test C-Index: {cindex(y_test.values, y_test_best)}\")"
      ],
      "metadata": {
        "id": "pE8gh4L9mT17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dropped_rows = X_train[X_train.isnull().any(axis=1)]\n",
        "\n",
        "columns_except_Systolic_BP = [col for col in X_train.columns if col not in ['Systolic BP']]\n",
        "\n",
        "for col in columns_except_Systolic_BP:\n",
        "    sns.distplot(X_train.loc[:, col], norm_hist=True, kde=False, label='full data')\n",
        "    sns.distplot(dropped_rows.loc[:, col], norm_hist=True, kde=False, label='without missing data')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "MrVdXaU1mT5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Error Analysis"
      ],
      "metadata": {
        "id": "ANo9ASEcmeGt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bad_subset(forest, X_test, y_test):\n",
        "    # define mask to select large subset with poor performance\n",
        "    # currently mask defines the entire set\n",
        "\n",
        "    mask = X_test['Age']>65\n",
        "\n",
        "    X_subgroup = X_test[mask]\n",
        "    y_subgroup = y_test[mask]\n",
        "    subgroup_size = len(X_subgroup)\n",
        "\n",
        "    y_subgroup_preds = forest.predict_proba(X_subgroup)[:, 1]\n",
        "    performance = cindex(y_subgroup.values, y_subgroup_preds)\n",
        "    \n",
        "    return performance, subgroup_size"
      ],
      "metadata": {
        "id": "3FIZ2JZUme-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "performance, subgroup_size = bad_subset(best_rf, X_test, y_test)\n",
        "print(\"Subgroup size should greater than 250, performance should be less than 0.69 \")\n",
        "print(f\"Subgroup size: {subgroup_size}, C-Index: {performance}\")"
      ],
      "metadata": {
        "id": "Qh9hX3Z-mfB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imputation Approaches"
      ],
      "metadata": {
        "id": "6ZEZMrSTmlnm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Impute values using the mean\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "imputer.fit(X_train)\n",
        "X_train_mean_imputed = pd.DataFrame(imputer.transform(X_train), columns=X_train.columns)\n",
        "X_val_mean_imputed = pd.DataFrame(imputer.transform(X_val), columns=X_val.columns)"
      ],
      "metadata": {
        "id": "gOA9S9skmfF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hyperparams = {\n",
        "    # how many trees should be in the forest (int)\n",
        "    'n_estimators': [10],\n",
        "\n",
        "    # the maximum depth of trees in the forest (int)\n",
        "    'max_depth': [4],\n",
        "\n",
        "    # the minimum number of samples in a leaf as a fraction\n",
        "    # of the total number of samples in the training set\n",
        "    # Can be int (in which case that is the minimum number)\n",
        "    # or float (in which case the minimum is that fraction of the\n",
        "    # number of training set samples)\n",
        "    'min_samples_leaf': [1]}"
      ],
      "metadata": {
        "id": "Ys1If3momsEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier()\n",
        "\n",
        "rf_mean_imputed, best_hyperparams_mean_imputed = holdout_grid_search(rf, X_train_mean_imputed, y_train,\n",
        "                                                                     X_val_mean_imputed, y_val,\n",
        "                                                                     hyperparams, {'random_state': 10})\n",
        "\n",
        "print(\"Performance for best hyperparameters:\")\n",
        "\n",
        "y_train_best = rf_mean_imputed.predict_proba(X_train_mean_imputed)[:, 1]\n",
        "print(f\"- Train C-Index: {cindex(y_train, y_train_best):.4f}\")\n",
        "\n",
        "y_val_best = rf_mean_imputed.predict_proba(X_val_mean_imputed)[:, 1]\n",
        "print(f\"- Val C-Index: {cindex(y_val, y_val_best):.4f}\")\n",
        "\n",
        "y_test_imp = rf_mean_imputed.predict_proba(X_test)[:, 1]\n",
        "print(f\"- Test C-Index: {cindex(y_test, y_test_imp):.4f}\")"
      ],
      "metadata": {
        "id": "AGWKQ9GzmsHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imputer = IterativeImputer(random_state=0, sample_posterior=False, max_iter=1, min_value=0)\n",
        "imputer.fit(X_train)\n",
        "X_train_imputed = pd.DataFrame(imputer.transform(X_train), columns=X_train.columns)\n",
        "X_val_imputed = pd.DataFrame(imputer.transform(X_val), columns=X_val.columns)"
      ],
      "metadata": {
        "id": "5f9rz5Jfm5_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hyperparams = {'n_estimators': [10],'max_depth': [4],'min_samples_leaf': [1]}"
      ],
      "metadata": {
        "id": "l1O05YPSqwtg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier()\n",
        "\n",
        "rf_imputed, best_hyperparams_imputed = holdout_grid_search(rf, X_train_imputed, y_train,\n",
        "                                                           X_val_imputed, y_val,\n",
        "                                                           hyperparams, {'random_state': 10})\n",
        "\n",
        "print(\"Performance for best hyperparameters:\")\n",
        "\n",
        "y_train_best = rf_imputed.predict_proba(X_train_imputed)[:, 1]\n",
        "print(f\"- Train C-Index: {cindex(y_train, y_train_best):.4f}\")\n",
        "\n",
        "y_val_best = rf_imputed.predict_proba(X_val_imputed)[:, 1]\n",
        "print(f\"- Val C-Index: {cindex(y_val, y_val_best):.4f}\")\n",
        "\n",
        "y_test_imp = rf_imputed.predict_proba(X_test)[:, 1]\n",
        "print(f\"- Test C-Index: {cindex(y_test, y_test_imp):.4f}\")"
      ],
      "metadata": {
        "id": "iiyL2ZzvqwxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "performance, subgroup_size = bad_subset(best_rf, X_test, y_test)\n",
        "print(f\"C-Index (no imputation): {performance}\")\n",
        "\n",
        "performance, subgroup_size = bad_subset(rf_mean_imputed, X_test, y_test)\n",
        "print(f\"C-Index (mean imputation): {performance}\")\n",
        "\n",
        "performance, subgroup_size = bad_subset(rf_imputed, X_test, y_test)\n",
        "print(f\"C-Index (multivariate feature imputation): {performance}\")"
      ],
      "metadata": {
        "id": "jDKelWe-q_5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_risk = X_test.copy(deep=True)\n",
        "X_test_risk.loc[:, 'risk'] = rf_imputed.predict_proba(X_test_risk)[:, 1]\n",
        "X_test_risk = X_test_risk.sort_values(by='risk', ascending=False)\n",
        "X_test_risk.head()"
      ],
      "metadata": {
        "id": "n4L1T63YrA04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "explainer = shap.TreeExplainer(rf_imputed)\n",
        "i = 0\n",
        "shap_value = explainer.shap_values(X_test.loc[X_test_risk.index[i], :])[1]\n",
        "shap.force_plot(explainer.expected_value[1], shap_value, feature_names=X_test.columns, matplotlib=True)"
      ],
      "metadata": {
        "id": "bOyGZQKFrA5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_values = shap.TreeExplainer(rf_imputed).shap_values(X_test)[1]\n",
        "\n",
        "shap.summary_plot(shap_values, X_test)"
      ],
      "metadata": {
        "id": "NChmU2UMrJff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap.dependence_plot('Age', shap_values, X_test, interaction_index='Sex')"
      ],
      "metadata": {
        "id": "4Y4rEpFHrJi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap.dependence_plot('Poverty index', shap_values, X_test, interaction_index='Age')"
      ],
      "metadata": {
        "id": "eAPUWJ0GrPKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FINISH"
      ],
      "metadata": {
        "id": "J-Zz_xJ0rRaZ"
      }
    }
  ]
}