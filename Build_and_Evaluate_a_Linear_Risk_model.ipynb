{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Build and Evaluate a Linear Risk model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GO8v7TYbh9Hz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data"
      ],
      "metadata": {
        "id": "koBkGdfAiJdi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from utils import load_data\n",
        "\n",
        "# This function creates randomly generated data\n",
        "# X, y = load_data(6000)\n",
        "\n",
        "# For stability, load data from files that were generated using the load_data\n",
        "X = pd.read_csv('X_data.csv',index_col=0)\n",
        "y_df = pd.read_csv('y_data.csv',index_col=0)\n",
        "y = y_df['y']"
      ],
      "metadata": {
        "id": "7kU1P-iNiG7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.head()"
      ],
      "metadata": {
        "id": "9eoUg8EqiG-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.head()"
      ],
      "metadata": {
        "id": "V3GnJfXRiHBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, train_size=0.75, random_state=0)"
      ],
      "metadata": {
        "id": "NeUZtF2riHEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in X.columns:\n",
        "    X_train_raw.loc[:, col].hist()\n",
        "    plt.title(col)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "_huTyy2UiHGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import norm\n",
        "data = np.random.normal(50,12, 5000)\n",
        "fitting_params = norm.fit(data)\n",
        "norm_dist_fitted = norm(*fitting_params)\n",
        "t = np.linspace(0,100, 100)\n",
        "plt.hist(data, bins=60, density=True)\n",
        "plt.plot(t, norm_dist_fitted.pdf(t))\n",
        "plt.title('Example of Normally Distributed Data')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Iwzef5BwiHJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in X_train_raw.columns:\n",
        "    np.log(X_train_raw.loc[:, col]).hist()\n",
        "    plt.title(col)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "mpFIn0g6icZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_standard_normal(df_train, df_test):\n",
        "    \"\"\"\n",
        "    In order to make the data closer to a normal distribution, take log\n",
        "    transforms to reduce the skew.\n",
        "    Then standardize the distribution with a mean of zero and standard deviation of 1. \n",
        "  \n",
        "    Args:\n",
        "      df_train (dataframe): unnormalized training data.\n",
        "      df_test (dataframe): unnormalized test data.\n",
        "  \n",
        "    Returns:\n",
        "      df_train_normalized (dateframe): normalized training data.\n",
        "      df_test_normalized (dataframe): normalized test data.\n",
        "    \"\"\"\n",
        " \n",
        "    # Remove skew by applying the log function to the train set, and to the test set\n",
        "    df_train_unskewed = np.log(df_train)\n",
        "    df_test_unskewed = np.log(df_test)\n",
        "    \n",
        "    #calculate the mean and standard deviation of the training set\n",
        "    mean = df_train_unskewed.mean()\n",
        "    stdev = df_train_unskewed.std(ddof=1)\n",
        "    \n",
        "    # standardize the training set\n",
        "    df_train_standardized = (df_train_unskewed-mean)/stdev\n",
        "    \n",
        "    # standardize the test set (see instructions and hints above)\n",
        "    df_test_standardized = (df_test_unskewed-mean)/stdev\n",
        "\n",
        "    return df_train_standardized, df_test_standardized"
      ],
      "metadata": {
        "id": "19TCxPcQicb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test = make_standard_normal(X_train_raw, X_test_raw)"
      ],
      "metadata": {
        "id": "a40IKNp-icgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in X_train.columns:\n",
        "    X_train[col].hist()\n",
        "    plt.title(col)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "mdsTmDtOiHLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the Model"
      ],
      "metadata": {
        "id": "f3lutNXRisEe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lr_model(X_train, y_train):\n",
        "\n",
        "    # import the LogisticRegression class\n",
        "    from sklearn.linear_model import LogisticRegression\n",
        "    \n",
        "    # create the model object\n",
        "    model = LogisticRegression()\n",
        "    \n",
        "    # fit the model to the training data\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "kMJ1_q3DiHOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_X = lr_model(X_train, y_train)"
      ],
      "metadata": {
        "id": "ue3uOLi0iHR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate the Model Using the C-index"
      ],
      "metadata": {
        "id": "Iq5CYOmei2QY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cindex(y_true, scores):\n",
        "    '''\n",
        "\n",
        "    Input:\n",
        "    y_true (np.array): a 1-D array of true binary outcomes (values of zero or one)\n",
        "        0: patient does not get the disease\n",
        "        1: patient does get the disease\n",
        "    scores (np.array): a 1-D array of corresponding risk scores output by the model\n",
        "\n",
        "    Output:\n",
        "    c_index (float): (concordant pairs + 0.5*ties) / number of permissible pairs\n",
        "    '''\n",
        "    n = len(y_true)\n",
        "    assert len(scores) == n\n",
        "\n",
        "    concordant = 0\n",
        "    permissible = 0\n",
        "    ties = 0\n",
        "\n",
        "    # use two nested for loops to go through all unique pairs of patients\n",
        "    for i in range(n):\n",
        "        for j in range(i+1, n): #choose the range of j so that j>i\n",
        "            \n",
        "            # Check if the pair is permissible (the patient outcomes are different)\n",
        "            if y_true[i]!=y_true[j]:\n",
        "                # Count the pair if it's permissible\n",
        "                permissible+=1\n",
        "\n",
        "                # For permissible pairs, check if they are concordant or are ties\n",
        "\n",
        "                # check for ties in the score\n",
        "                if scores[i]==scores[j]:\n",
        "                    # count the tie\n",
        "                    ties+=1\n",
        "                    # if it's a tie, we don't need to check patient outcomes, continue to the top of the for loop.\n",
        "                    continue\n",
        "\n",
        "                # case 1: patient i doesn't get the disease, patient j does\n",
        "                if y_true[i] == 0 and y_true[j] == 1:\n",
        "                    # Check if patient i has a lower risk score than patient j\n",
        "                    if scores[i]<scores[j]:\n",
        "                        # count the concordant pair\n",
        "                        concordant+=1\n",
        "                    # Otherwise if patient i has a higher risk score, it's not a concordant pair.\n",
        "                    # Already checked for ties earlier\n",
        "\n",
        "                # case 2: patient i gets the disease, patient j does not\n",
        "                if y_true[i]==1 and y_true[j] == 0:\n",
        "                    # Check if patient i has a higher risk score than patient j\n",
        "                    if scores[i]>scores[j]:\n",
        "                        #count the concordant pair\n",
        "                        concordant+=1\n",
        "                    # Otherwise if patient i has a lower risk score, it's not a concordant pair.\n",
        "                    # We already checked for ties earlier\n",
        "\n",
        "    # calculate the c-index using the count of permissible pairs, concordant pairs, and tied pairs.\n",
        "    c_index = (concordant+(0.5*ties))/permissible\n",
        "    \n",
        "    return c_index"
      ],
      "metadata": {
        "id": "Pt-hUMZYi3NG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model_X.predict_proba(X_test)[:, 1]\n",
        "c_index_X_test = cindex(y_test.values, scores)\n",
        "print(f\"c-index on test set is {c_index_X_test:.4f}\")"
      ],
      "metadata": {
        "id": "lnsrmQTQi3Pz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coeffs = pd.DataFrame(data = model_X.coef_, columns = X_train.columns)\n",
        "coeffs.T.plot.bar(legend=None)"
      ],
      "metadata": {
        "id": "5a-5R51fi3SV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Improve the Model"
      ],
      "metadata": {
        "id": "hzEJBaVAjFrQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_interactions(X):\n",
        "    \"\"\"\n",
        "    Add interaction terms between columns to dataframe.\n",
        "\n",
        "    Args:\n",
        "    X (dataframe): Original data\n",
        "\n",
        "    Returns:\n",
        "    X_int (dataframe): Original data with interaction terms appended. \n",
        "    \"\"\"\n",
        "    features = X.columns\n",
        "    m = len(features)\n",
        "    X_int = X.copy(deep=True)\n",
        "\n",
        "    # 'i' loops through all features in the original dataframe X\n",
        "    for i in range(m-1):\n",
        "        \n",
        "        # get the name of feature 'i'\n",
        "        feature_i_name = features[i]\n",
        "        \n",
        "        # get the data for feature 'i']\n",
        "        \n",
        "        # choose the index of column 'j' to be greater than column i\n",
        "        for j in range(i+1, m):\n",
        "            \n",
        "            # get the name of feature 'j'\n",
        "            feature_j_name = features[j]\n",
        "            \n",
        "            # get the data for feature j'\n",
        "            feature_j_data = X_int[feature_i_name]\n",
        "            \n",
        "            # create the name of the interaction feature by combining both names\n",
        "            # example: \"apple\" and \"orange\" are combined to be \"apple_x_orange\"\n",
        "            feature_i_j_name = f'{feature_i_name}_x_{feature_j_name}'\n",
        "            \n",
        "            # Multiply the data for feature 'i' and feature 'j'\n",
        "            # store the result as a column in dataframe X_int\n",
        "            X_int[feature_i_j_name] = X_int[feature_i_name]*X_int[feature_j_name]\n",
        "\n",
        "    return X_int"
      ],
      "metadata": {
        "id": "3y33bFXZjItV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Original Data\")\n",
        "print(X_train.loc[:, ['Age', 'Systolic_BP']].head())\n",
        "print(\"Data w/ Interactions\")\n",
        "print(add_interactions(X_train.loc[:, ['Age', 'Systolic_BP']].head()))"
      ],
      "metadata": {
        "id": "gpK6UDxzjMye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate the Improved Model"
      ],
      "metadata": {
        "id": "rLXTCVf7jPAX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_X_int = lr_model(X_train_int, y_train)"
      ],
      "metadata": {
        "id": "k4MphXd5jM3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores_X = model_X.predict_proba(X_test)[:, 1]\n",
        "c_index_X_int_test = cindex(y_test.values, scores_X)\n",
        "\n",
        "scores_X_int = model_X_int.predict_proba(X_test_int)[:, 1]\n",
        "c_index_X_int_test = cindex(y_test.values, scores_X_int)\n",
        "\n",
        "print(f\"c-index on test set without interactions is {c_index_X_test:.4f}\")\n",
        "print(f\"c-index on test set with interactions is {c_index_X_int_test:.4f}\")"
      ],
      "metadata": {
        "id": "z4t9awUFjRqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "int_coeffs = pd.DataFrame(data = model_X_int.coef_, columns = X_train_int.columns)\n",
        "int_coeffs.T.plot.bar()"
      ],
      "metadata": {
        "id": "5C7JH35PjRwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FINISH"
      ],
      "metadata": {
        "id": "BMwhFvQRjb9O"
      }
    }
  ]
}